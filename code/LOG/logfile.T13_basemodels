{'text/html': "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>", 'text/vnd.plotly.v1+html': "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"}
--> Work on ID:  T13_basemodels
---> our model pipline is created
train shape is   (903653, 39)
test shape is   (804684, 38)
---> models we used include: lgb
---> models we used include: lasso
---> models we used include: elasticNet
---> models we used include: gboost
---> models we used include: xgboost
 ---> Work on CV for lgb 
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
  time spent:  722.4432532787323
 ---> Work on CV for lasso 
  time spent:  27.67240595817566
 ---> Work on CV for elasticNet 
  time spent:  26.59100580215454
 ---> Work on CV for gboost 
  time spent:  259.3716170787811
 ---> Work on CV for xgboost 
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
  time spent:  2313.275942325592
 ---> Work on train&Predict for LGBMRegressor(bagging_fraction=0.7, bagging_seed=2018, boosting_type='gbdt',
       class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
       importance_type='split', learning_rate=0.1, max_depth=-1,
       min_child_samples=100, min_child_weight=0.001, min_split_gain=0.0,
       n_estimators=100, n_jobs=-1, num_leaves=30, objective=None,
       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,
       subsample=1.0, subsample_for_bin=200000, subsample_freq=0) 
 ---> Work on train&Predict for Pipeline(memory=None,
     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,
       with_scaling=True)), ('lasso', Lasso(alpha=0.0005, copy_X=True, fit_intercept=True, max_iter=1000,
   normalize=False, positive=False, precompute=False, random_state=1,
   selection='cyclic', tol=0.0001, warm_start=False))]) 
 ---> Work on train&Predict for Pipeline(memory=None,
     steps=[('robustscaler', RobustScaler(copy=True, quantile_range=(25.0, 75.0), with_centering=True,
       with_scaling=True)), ('elasticnet', ElasticNet(alpha=0.0005, copy_X=True, fit_intercept=True, l1_ratio=0.9,
      max_iter=1000, normalize=False, positive=False, precompute=False,
      random_state=3, selection='cyclic', tol=0.0001, warm_start=False))]) 
 ---> Work on train&Predict for GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.05, loss='huber', max_depth=4,
             max_features='sqrt', max_leaf_nodes=None,
             min_impurity_decrease=0.0, min_impurity_split=None,
             min_samples_leaf=15, min_samples_split=10,
             min_weight_fraction_leaf=0.0, n_estimators=3000,
             presort='auto', random_state=5, subsample=1.0, verbose=0,
             warm_start=False) 
 ---> Work on train&Predict for XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,
       colsample_bytree=0.4603, gamma=0.0468, learning_rate=0.05,
       max_delta_step=0, max_depth=3, min_child_weight=1.7817,
       missing=None, n_estimators=2200, n_jobs=1, nthread=-1,
       objective='reg:linear', random_state=7, reg_alpha=0.464,
       reg_lambda=0.8571, scale_pos_weight=1, seed=None, silent=1,
       subsample=0.5213) 
Traceback (most recent call last):
  File "/home/ubuntu/Kaggle_GCRevenuePrediction/code/run.py", line 20, in <module>
    my_train.run()
  File "/home/ubuntu/Kaggle_GCRevenuePrediction/code/model_train.py", line 132, in run
    self.train_predict()
  File "/home/ubuntu/Kaggle_GCRevenuePrediction/code/model_train.py", line 244, in train_predict
    model.fit(self.train_x,self.train_y)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py", line 289, in fit
    trainDmatrix = DMatrix(X, label=y, missing=self.missing, nthread=self.n_jobs)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/xgboost/core.py", line 344, in __init__
    feature_types)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/xgboost/core.py", line 214, in _maybe_pandas_data
    raise ValueError(msg + ', '.join(bad_fields))
ValueError: DataFrame.dtypes for data must be int, float or bool.
                Did not expect the data types in fields networkDomain
