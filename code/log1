{'text/html': "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>", 'text/vnd.plotly.v1+html': "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"}
--> Work on ID:  T1_all_cpu_all_model
---> our model pipline is created
train shape is   (903653, 39)
test shape is   (804684, 38)
---> models we used include: lgb
---> models we used include: lasso
---> models we used include: elasticNet
---> models we used include: gboost
---> models we used include: xgboost
 ---> Work on CV for lgb 
[LightGBM] [Warning] Unknown parameter: bagging_frequency
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] Unknown parameter: bagging_frequency
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
multiprocessing.pool.RemoteTraceback: 
"""
Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 350, in __call__
    return self.func(*args, **kwargs)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in __call__
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 131, in <listcomp>
    return [func(*args, **kwargs) for func, args, kwargs in self.items]
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 449, in _fit_and_score
    X_test, y_test = _safe_split(estimator, X, y, test, train)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py", line 200, in _safe_split
    X_subset = safe_indexing(X, indices)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py", line 160, in safe_indexing
    return X.take(indices, axis=0)
MemoryError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py", line 359, in __call__
    raise TransportableException(text, e_type)
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
MemoryError                                        Tue Oct 30 18:39:43 2018
PID: 1972                 Python 3.6.5: /home/ubuntu/anaconda3/bin//python3
...........................................................................
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (LGBMRegressor(bagging_fraction=0.7, bagging_freq...ubsample_for_bin=200000,
       subsample_freq=0), array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object), 0         0.0
1         0.0
2         0.0
3     ...ransactionRevenue, Length: 903653, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([255510,  90448, 377381, ..., 570257, 367064, 173628]), memmap([539654, 278144, 543925, ..., 831235, 536041, 128308]), 0, None, None), {'return_times': True, 'return_train_score': False})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (LGBMRegressor(bagging_fraction=0.7, bagging_freq...ubsample_for_bin=200000,
       subsample_freq=0), array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object), 0         0.0
1         0.0
2         0.0
3     ...ransactionRevenue, Length: 903653, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([255510,  90448, 377381, ..., 570257, 367064, 173628]), memmap([539654, 278144, 543925, ..., 831235, 536041, 128308]), 0, None, None)
        kwargs = {'return_times': True, 'return_train_score': False}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq...ubsample_for_bin=200000,
       subsample_freq=0), X=array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object), y=0         0.0
1         0.0
2         0.0
3     ...ransactionRevenue, Length: 903653, dtype: float64, scorer={'score': make_scorer(mean_squared_error, greater_is_better=False)}, train=memmap([255510,  90448, 377381, ..., 570257, 367064, 173628]), test=memmap([539654, 278144, 543925, ..., 831235, 536041, 128308]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')
    444         estimator.set_params(**parameters)
    445 
    446     start_time = time.time()
    447 
    448     X_train, y_train = _safe_split(estimator, X, y, train)
--> 449     X_test, y_test = _safe_split(estimator, X, y, test, train)
        X_test = undefined
        y_test = undefined
        estimator = LGBMRegressor(bagging_fraction=0.7, bagging_freq...ubsample_for_bin=200000,
       subsample_freq=0)
        X = array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object)
        y = 0         0.0
1         0.0
2         0.0
3     ...ransactionRevenue, Length: 903653, dtype: float64
        test = memmap([539654, 278144, 543925, ..., 831235, 536041, 128308])
        train = memmap([255510,  90448, 377381, ..., 570257, 367064, 173628])
    450 
    451     is_multimetric = not callable(scorer)
    452     n_scorers = len(scorer.keys()) if is_multimetric else 1
    453 

...........................................................................
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq...ubsample_for_bin=200000,
       subsample_freq=0), X=array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object), y=0         0.0
1         0.0
2         0.0
3     ...ransactionRevenue, Length: 903653, dtype: float64, indices=memmap([539654, 278144, 543925, ..., 831235, 536041, 128308]), train_indices=memmap([255510,  90448, 377381, ..., 570257, 367064, 173628]))
    195         if train_indices is None:
    196             X_subset = X[np.ix_(indices, indices)]
    197         else:
    198             X_subset = X[np.ix_(indices, train_indices)]
    199     else:
--> 200         X_subset = safe_indexing(X, indices)
        X_subset = undefined
        X = array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object)
        indices = memmap([539654, 278144, 543925, ..., 831235, 536041, 128308])
    201 
    202     if y is not None:
    203         y_subset = safe_indexing(y, indices)
    204     else:

...........................................................................
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object), indices=memmap([539654, 278144, 543925, ..., 831235, 536041, 128308]))
    155             return X.copy().iloc[indices]
    156     elif hasattr(X, "shape"):
    157         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and
    158                                    indices.dtype.kind == 'i'):
    159             # This is often substantially faster than X[indices]
--> 160             return X.take(indices, axis=0)
        X.take = <built-in method take of numpy.ndarray object>
        indices = memmap([539654, 278144, 543925, ..., 831235, 536041, 128308])
    161         else:
    162             return X[indices]
    163     else:
    164         return [X[idx] for idx in indices]

MemoryError: 
___________________________________________________________________________
"""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 699, in retrieve
    self._output.extend(job.get(timeout=self.timeout))
  File "/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/pool.py", line 644, in get
    raise self._value
sklearn.externals.joblib.my_exceptions.TransportableException: TransportableException
___________________________________________________________________________
MemoryError                                        Tue Oct 30 18:39:43 2018
PID: 1972                 Python 3.6.5: /home/ubuntu/anaconda3/bin//python3
...........................................................................
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (LGBMRegressor(bagging_fraction=0.7, bagging_freq...ubsample_for_bin=200000,
       subsample_freq=0), array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object), 0         0.0
1         0.0
2         0.0
3     ...ransactionRevenue, Length: 903653, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([255510,  90448, 377381, ..., 570257, 367064, 173628]), memmap([539654, 278144, 543925, ..., 831235, 536041, 128308]), 0, None, None), {'return_times': True, 'return_train_score': False})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (LGBMRegressor(bagging_fraction=0.7, bagging_freq...ubsample_for_bin=200000,
       subsample_freq=0), array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object), 0         0.0
1         0.0
2         0.0
3     ...ransactionRevenue, Length: 903653, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([255510,  90448, 377381, ..., 570257, 367064, 173628]), memmap([539654, 278144, 543925, ..., 831235, 536041, 128308]), 0, None, None)
        kwargs = {'return_times': True, 'return_train_score': False}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq...ubsample_for_bin=200000,
       subsample_freq=0), X=array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object), y=0         0.0
1         0.0
2         0.0
3     ...ransactionRevenue, Length: 903653, dtype: float64, scorer={'score': make_scorer(mean_squared_error, greater_is_better=False)}, train=memmap([255510,  90448, 377381, ..., 570257, 367064, 173628]), test=memmap([539654, 278144, 543925, ..., 831235, 536041, 128308]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')
    444         estimator.set_params(**parameters)
    445 
    446     start_time = time.time()
    447 
    448     X_train, y_train = _safe_split(estimator, X, y, train)
--> 449     X_test, y_test = _safe_split(estimator, X, y, test, train)
        X_test = undefined
        y_test = undefined
        estimator = LGBMRegressor(bagging_fraction=0.7, bagging_freq...ubsample_for_bin=200000,
       subsample_freq=0)
        X = array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object)
        y = 0         0.0
1         0.0
2         0.0
3     ...ransactionRevenue, Length: 903653, dtype: float64
        test = memmap([539654, 278144, 543925, ..., 831235, 536041, 128308])
        train = memmap([255510,  90448, 377381, ..., 570257, 367064, 173628])
    450 
    451     is_multimetric = not callable(scorer)
    452     n_scorers = len(scorer.keys()) if is_multimetric else 1
    453 

...........................................................................
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq...ubsample_for_bin=200000,
       subsample_freq=0), X=array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object), y=0         0.0
1         0.0
2         0.0
3     ...ransactionRevenue, Length: 903653, dtype: float64, indices=memmap([539654, 278144, 543925, ..., 831235, 536041, 128308]), train_indices=memmap([255510,  90448, 377381, ..., 570257, 367064, 173628]))
    195         if train_indices is None:
    196             X_subset = X[np.ix_(indices, indices)]
    197         else:
    198             X_subset = X[np.ix_(indices, train_indices)]
    199     else:
--> 200         X_subset = safe_indexing(X, indices)
        X_subset = undefined
        X = array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object)
        indices = memmap([539654, 278144, 543925, ..., 831235, 536041, 128308])
    201 
    202     if y is not None:
    203         y_subset = safe_indexing(y, indices)
    204     else:

...........................................................................
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object), indices=memmap([539654, 278144, 543925, ..., 831235, 536041, 128308]))
    155             return X.copy().iloc[indices]
    156     elif hasattr(X, "shape"):
    157         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and
    158                                    indices.dtype.kind == 'i'):
    159             # This is often substantially faster than X[indices]
--> 160             return X.take(indices, axis=0)
        X.take = <built-in method take of numpy.ndarray object>
        indices = memmap([539654, 278144, 543925, ..., 831235, 536041, 128308])
    161         else:
    162             return X[indices]
    163     else:
    164         return [X[idx] for idx in indices]

MemoryError: 
___________________________________________________________________________

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "./gc.py", line 20, in <module>
    my_train.run()
  File "/home/ubuntu/Kaggle_GCRevenuePrediction/code/model_train.py", line 129, in run
    self.cv_models()
  File "/home/ubuntu/Kaggle_GCRevenuePrediction/code/model_train.py", line 222, in cv_models
    cv = cv_split))
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 342, in cross_val_score
    pre_dispatch=pre_dispatch)
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py", line 206, in cross_validate
    for train, test in cv.split(X, y, groups))
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 789, in __call__
    self.retrieve()
  File "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py", line 740, in retrieve
    raise exception
sklearn.externals.joblib.my_exceptions.JoblibMemoryError: JoblibMemoryError
___________________________________________________________________________
Multiprocessing exception:
...........................................................................
/home/ubuntu/Kaggle_GCRevenuePrediction/code/gc.py in <module>()
     15 train_df = pd.read_hdf("../data/train_df.h5",key="train_df")
     16 test_df = pd.read_hdf("../data/test_df.h5",key="test_df")
     17 
     18 
     19 my_train = lets_train(train_df,test_df,'totals.transactionRevenue',work_id)
---> 20 my_train.run()

...........................................................................
/home/ubuntu/Kaggle_GCRevenuePrediction/code/model_train.py in run(self=<model_train.lets_train object>)
    124         
    125         # 1. define the modes that we want to use
    126         self.define_models()
    127         
    128         # 2. cross-validate the models that we selected
--> 129         self.cv_models()
        self.cv_models = <bound method lets_train.cv_models of <model_train.lets_train object>>
    130         
    131         # 3. use models to train and predict
    132         self.train_predict()
    133         

...........................................................................
/home/ubuntu/Kaggle_GCRevenuePrediction/code/model_train.py in cv_models(self=<model_train.lets_train object>)
    217             print(" ---> Work on CV for %s "% model_name)
    218             
    219             start = time.time()
    220             rmse = np.sqrt(-cross_val_score(model,self.train_x.values,self.train_y,
    221                                            scoring='neg_mean_squared_error',
--> 222                                            cv = cv_split))
        cv_split = ShuffleSplit(n_splits=3, random_state=43, test_size=0.3, train_size=0.7)
    223                                            ##cv = cv_split,n_jobs=-1))
    224             end = time.time()
    225             print("  time spent: ", end-start)
    226 

...........................................................................
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in cross_val_score(estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq...ubsample_for_bin=200000,
       subsample_freq=0), X=array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object), y=0         0.0
1         0.0
2         0.0
3     ...ransactionRevenue, Length: 903653, dtype: float64, groups=None, scoring='neg_mean_squared_error', cv=ShuffleSplit(n_splits=3, random_state=43, test_size=0.3, train_size=0.7), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')
    337     cv_results = cross_validate(estimator=estimator, X=X, y=y, groups=groups,
    338                                 scoring={'score': scorer}, cv=cv,
    339                                 return_train_score=False,
    340                                 n_jobs=n_jobs, verbose=verbose,
    341                                 fit_params=fit_params,
--> 342                                 pre_dispatch=pre_dispatch)
        pre_dispatch = '2*n_jobs'
    343     return cv_results['test_score']
    344 
    345 
    346 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,

...........................................................................
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in cross_validate(estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq...ubsample_for_bin=200000,
       subsample_freq=0), X=array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object), y=0         0.0
1         0.0
2         0.0
3     ...ransactionRevenue, Length: 903653, dtype: float64, groups=None, scoring={'score': make_scorer(mean_squared_error, greater_is_better=False)}, cv=ShuffleSplit(n_splits=3, random_state=43, test_size=0.3, train_size=0.7), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False)
    201     scores = parallel(
    202         delayed(_fit_and_score)(
    203             clone(estimator), X, y, scorers, train, test, verbose, None,
    204             fit_params, return_train_score=return_train_score,
    205             return_times=True)
--> 206         for train, test in cv.split(X, y, groups))
        cv.split = <bound method BaseShuffleSplit.split of ShuffleS... random_state=43, test_size=0.3, train_size=0.7)>
        X = array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object)
        y = 0         0.0
1         0.0
2         0.0
3     ...ransactionRevenue, Length: 903653, dtype: float64
        groups = None
    207 
    208     if return_train_score:
    209         train_scores, test_scores, fit_times, score_times = zip(*scores)
    210         train_scores = _aggregate_score_dicts(train_scores)

...........................................................................
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object cross_validate.<locals>.<genexpr>>)
    784             if pre_dispatch == "all" or n_jobs == 1:
    785                 # The iterable was consumed all at once by the above for loop.
    786                 # No need to wait for async callbacks to trigger to
    787                 # consumption.
    788                 self._iterating = False
--> 789             self.retrieve()
        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>
    790             # Make sure that we get a last message telling us we are done
    791             elapsed_time = time.time() - self._start_time
    792             self._print('Done %3i out of %3i | elapsed: %s finished',
    793                         (len(self._output), len(self._output),

---------------------------------------------------------------------------
Sub-process traceback:
---------------------------------------------------------------------------
MemoryError                                        Tue Oct 30 18:39:43 2018
PID: 1972                 Python 3.6.5: /home/ubuntu/anaconda3/bin//python3
...........................................................................
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        self.items = [(<function _fit_and_score>, (LGBMRegressor(bagging_fraction=0.7, bagging_freq...ubsample_for_bin=200000,
       subsample_freq=0), array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object), 0         0.0
1         0.0
2         0.0
3     ...ransactionRevenue, Length: 903653, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([255510,  90448, 377381, ..., 570257, 367064, 173628]), memmap([539654, 278144, 543925, ..., 831235, 536041, 128308]), 0, None, None), {'return_times': True, 'return_train_score': False})]
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)
    126     def __init__(self, iterator_slice):
    127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 
    130     def __call__(self):
--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]
        func = <function _fit_and_score>
        args = (LGBMRegressor(bagging_fraction=0.7, bagging_freq...ubsample_for_bin=200000,
       subsample_freq=0), array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object), 0         0.0
1         0.0
2         0.0
3     ...ransactionRevenue, Length: 903653, dtype: float64, {'score': make_scorer(mean_squared_error, greater_is_better=False)}, memmap([255510,  90448, 377381, ..., 570257, 367064, 173628]), memmap([539654, 278144, 543925, ..., 831235, 536041, 128308]), 0, None, None)
        kwargs = {'return_times': True, 'return_train_score': False}
    132 
    133     def __len__(self):
    134         return self._size
    135 

...........................................................................
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq...ubsample_for_bin=200000,
       subsample_freq=0), X=array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object), y=0         0.0
1         0.0
2         0.0
3     ...ransactionRevenue, Length: 903653, dtype: float64, scorer={'score': make_scorer(mean_squared_error, greater_is_better=False)}, train=memmap([255510,  90448, 377381, ..., 570257, 367064, 173628]), test=memmap([539654, 278144, 543925, ..., 831235, 536041, 128308]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=True, error_score='raise')
    444         estimator.set_params(**parameters)
    445 
    446     start_time = time.time()
    447 
    448     X_train, y_train = _safe_split(estimator, X, y, train)
--> 449     X_test, y_test = _safe_split(estimator, X, y, test, train)
        X_test = undefined
        y_test = undefined
        estimator = LGBMRegressor(bagging_fraction=0.7, bagging_freq...ubsample_for_bin=200000,
       subsample_freq=0)
        X = array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object)
        y = 0         0.0
1         0.0
2         0.0
3     ...ransactionRevenue, Length: 903653, dtype: float64
        test = memmap([539654, 278144, 543925, ..., 831235, 536041, 128308])
        train = memmap([255510,  90448, 377381, ..., 570257, 367064, 173628])
    450 
    451     is_multimetric = not callable(scorer)
    452     n_scorers = len(scorer.keys()) if is_multimetric else 1
    453 

...........................................................................
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/utils/metaestimators.py in _safe_split(estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq...ubsample_for_bin=200000,
       subsample_freq=0), X=array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object), y=0         0.0
1         0.0
2         0.0
3     ...ransactionRevenue, Length: 903653, dtype: float64, indices=memmap([539654, 278144, 543925, ..., 831235, 536041, 128308]), train_indices=memmap([255510,  90448, 377381, ..., 570257, 367064, 173628]))
    195         if train_indices is None:
    196             X_subset = X[np.ix_(indices, indices)]
    197         else:
    198             X_subset = X[np.ix_(indices, train_indices)]
    199     else:
--> 200         X_subset = safe_indexing(X, indices)
        X_subset = undefined
        X = array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object)
        indices = memmap([539654, 278144, 543925, ..., 831235, 536041, 128308])
    201 
    202     if y is not None:
    203         y_subset = safe_indexing(y, indices)
    204     else:

...........................................................................
/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/utils/__init__.py in safe_indexing(X=array([[4, 1.0, 1472830385.0, ..., 15, 5, 1],
  ... 1.0, 1483574474.0, ..., 0, 4, 0]], dtype=object), indices=memmap([539654, 278144, 543925, ..., 831235, 536041, 128308]))
    155             return X.copy().iloc[indices]
    156     elif hasattr(X, "shape"):
    157         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and
    158                                    indices.dtype.kind == 'i'):
    159             # This is often substantially faster than X[indices]
--> 160             return X.take(indices, axis=0)
        X.take = <built-in method take of numpy.ndarray object>
        indices = memmap([539654, 278144, 543925, ..., 831235, 536041, 128308])
    161         else:
    162             return X[indices]
    163     else:
    164         return [X[idx] for idx in indices]

MemoryError: 
___________________________________________________________________________
